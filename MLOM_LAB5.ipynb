{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZseni2oecYa",
        "outputId": "dbf0259e-7d9f-4082-e65b-02f65c0714dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# https://keras.io/api/layers/recurrent_layers/lstm/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Practical Materials - Lab 5/Practical Materials - Lab 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOYj-zRF5GpG",
        "outputId": "3c351bfc-7225-42ba-f305-b3e20f2603ba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Practical Materials - Lab 5/Practical Materials - Lab 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib-venn\n",
        "!pip install np_utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPordXGl7XW2",
        "outputId": "15970d87-3a3d-4397-d73b-79f3cb9f6a68"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib-venn in /usr/local/lib/python3.10/dist-packages (0.11.9)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from matplotlib-venn) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from matplotlib-venn) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from matplotlib-venn) (1.11.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->matplotlib-venn) (1.16.0)\n",
            "Requirement already satisfied: np_utils in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.10/dist-packages (from np_utils) (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# from tensorflow.keras.utils import np_utils\n",
        "# from keras.utils.np_utils import to_categorical\n",
        "utils.to_categorical"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQbaWPW47ibb",
        "outputId": "cae8d83d-13dd-410d-a0fe-8745a4043e28"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function keras.src.utils.np_utils.to_categorical(y, num_classes=None, dtype='float32')>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load the ascii text and conver to lowercase**"
      ],
      "metadata": {
        "id": "X2GFFQ1Q81ZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"data.txt\"\n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()"
      ],
      "metadata": {
        "id": "d9Z8RwE-7ws-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load the 1st 100 words**\n",
        "Indexing start with 0"
      ],
      "metadata": {
        "id": "b-7KlVfh9B2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we can change this according to our priority\n",
        "raw_text[0:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "YVWDkW4z8IKi",
        "outputId": "52f351f5-58ee-4f02-d34e-72b78ec2deba"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"project gutenberg's alice's adventures in wonderland, by lewis carroll\\n\\nthis ebook is for the use of\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **TO DO :**\n",
        "preprocess the data set and remove unwanted characters"
      ],
      "metadata": {
        "id": "8oqcqopo9UsO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EXynrAdp8UYA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Creating the caharacters in to numerical characters, we need to use the dictionary**"
      ],
      "metadata": {
        "id": "7PeOcOS_9f7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(raw_text)))\n",
        "print(chars)\n",
        "print(len(chars))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clFjgKSP9tuz",
        "outputId": "f45ac454-5f55-4ae1-f266-1360399e9f40"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', ' ', '!', '\"', '#', '$', '%', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '@', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_int = dict((c,i) for i,c in enumerate(chars))\n",
        "print(char_to_int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcJShYZp91Zi",
        "outputId": "bc52d27c-c4a1-4f99-e515-0dcd49743a6a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, '#': 4, '$': 5, '%': 6, \"'\": 7, '(': 8, ')': 9, '*': 10, ',': 11, '-': 12, '.': 13, '/': 14, '0': 15, '1': 16, '2': 17, '3': 18, '4': 19, '5': 20, '6': 21, '7': 22, '8': 23, '9': 24, ':': 25, ';': 26, '?': 27, '@': 28, '[': 29, ']': 30, '_': 31, 'a': 32, 'b': 33, 'c': 34, 'd': 35, 'e': 36, 'f': 37, 'g': 38, 'h': 39, 'i': 40, 'j': 41, 'k': 42, 'l': 43, 'm': 44, 'n': 45, 'o': 46, 'p': 47, 'q': 48, 'r': 49, 's': 50, 't': 51, 'u': 52, 'v': 53, 'w': 54, 'x': 55, 'y': 56, 'z': 57}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Claculate how many characters and words in this text file**"
      ],
      "metadata": {
        "id": "hE08L61l-fqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "\n",
        "print(\"Total Characters : \", n_chars)\n",
        "\n",
        "print(\"Total Vocab : Unique characters : \", n_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UL17f19-JR8",
        "outputId": "40cba5f5-df38-4b5d-fdad-2321d4249c6a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Characters :  163780\n",
            "Total Vocab : Unique characters :  58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this exercise we will split the book text up into subsequences with a fixed length of 100 characters..\n",
        "after going 100 characters we are going to predict next character..\n",
        "\n",
        "ex :- CHAPTER (SEQ LEN = 5)\n",
        "CHAPT -> E HAPTE -> R"
      ],
      "metadata": {
        "id": "VfQAU6r6_bpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TO DO\n",
        "#Change the value of sequence length and check the training dataset\n",
        "#Can also add test dataset"
      ],
      "metadata": {
        "id": "PrUciTlq-_O8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare the dataset of imput to output pairs encoded as integers\n",
        "\n",
        "seq_length = 100  #can changed\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "  seq_in = raw_text[i:i + seq_length]\n",
        "  seq_out = raw_text[i + seq_length]\n",
        "  dataX.append([char_to_int[char] for char in seq_in])\n",
        "  dataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataY)\n",
        "print(\"Total Patterns : \", n_patterns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5CfukfDCjaa",
        "outputId": "8a24c434-2421-483b-f213-edfbb1e1e3fa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Patterns :  163680\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataX[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWn3M0XTDkuc",
        "outputId": "f633e93b-a27f-4161-a414-02567acdfe47"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 39, 36, 43, 47, 1, 47, 49, 46, 35, 52, 34, 36, 1, 46, 52, 49, 1, 45, 36, 54, 1, 36, 33, 46, 46, 42, 50, 11, 1, 32, 45, 35, 1, 39, 46, 54, 1, 51, 46, 0, 50, 52, 33, 50, 34, 49, 40, 33, 36, 1, 51, 46, 1, 46, 52, 49, 1, 36, 44, 32, 40, 43, 1, 45, 36, 54, 50, 43, 36, 51, 51, 36, 49, 1, 51, 46, 1, 39, 36, 32, 49, 1, 32, 33, 46, 52, 51, 1, 45, 36, 54, 1, 36, 33, 46, 46, 42, 50, 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataY[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yu1ccCIzMzuC",
        "outputId": "082c927e-472d-4be5-ae26-ca8187fc1fc3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transform the list of input sequences into the form [samples, time steps, features] that is expected by an\n",
        "LSTM network and rescale the integers to the range [0,1] to make the patterns easier to learn by the LSTM\n",
        "network that uses the sigmoid activation function by default."
      ],
      "metadata": {
        "id": "JlDge56mNUph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#one hot encoding\n",
        "#taking y values from 0 to 1\n",
        "\n",
        "#resharp X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX,(n_patterns, seq_length,1))\n",
        "\n",
        "#normalize-rescaling the integer values\n",
        "X = X / float(n_vocab)\n",
        "print('X : \\n', X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNZhNaoWM5c2",
        "outputId": "e4b735e5-2ad3-4c9c-8c26-36ccabf5c3a8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X : \n",
            " [[[0.81034483]\n",
            "  [0.84482759]\n",
            "  [0.79310345]\n",
            "  ...\n",
            "  [0.01724138]\n",
            "  [0.79310345]\n",
            "  [0.63793103]]\n",
            "\n",
            " [[0.84482759]\n",
            "  [0.79310345]\n",
            "  [0.70689655]\n",
            "  ...\n",
            "  [0.79310345]\n",
            "  [0.63793103]\n",
            "  [0.01724138]]\n",
            "\n",
            " [[0.79310345]\n",
            "  [0.70689655]\n",
            "  [0.62068966]\n",
            "  ...\n",
            "  [0.63793103]\n",
            "  [0.01724138]\n",
            "  [0.55172414]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.87931034]\n",
            "  [0.79310345]\n",
            "  [0.01724138]\n",
            "  ...\n",
            "  [0.79310345]\n",
            "  [0.79310345]\n",
            "  [0.72413793]]\n",
            "\n",
            " [[0.79310345]\n",
            "  [0.01724138]\n",
            "  [0.67241379]\n",
            "  ...\n",
            "  [0.79310345]\n",
            "  [0.72413793]\n",
            "  [0.86206897]]\n",
            "\n",
            " [[0.01724138]\n",
            "  [0.67241379]\n",
            "  [0.62068966]\n",
            "  ...\n",
            "  [0.72413793]\n",
            "  [0.86206897]\n",
            "  [0.22413793]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert the output values (single characters converted to integers) into a one hot encoding.\n",
        "y = utils.to_categorical(dataY)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eFK2tOzOEcN",
        "outputId": "06913c67-463c-4d9f-d0d4-e1d8b936af91"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TO DO\n",
        "#Change the configuration of the model\n",
        "#(adding more layers, change LSTM units, change Dropout values, optimizor function)"
      ],
      "metadata": {
        "id": "KGk05aZ_QHpO"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define the LSTM model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(256,input_shape=(X.shape[1], X.shape[2]))) #can have 1 or more training samples\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
        "\n",
        "#define the checkpoint\n",
        "filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "#you can remove \"-{epoch:02d}-{loss:.4f}.hdf5\" AND GIVE \"weights-improvement\" ONLY\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min'),\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "#checkpoint - 1st epoch lower validation accuracy\n",
        "              # 2nd higher validation accuracy\n",
        "              # 3rd lower validation accuracy"
      ],
      "metadata": {
        "id": "vvRu6lrdRWgJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the model to data\n",
        "epochs = 3\n",
        "batch_size = 128"
      ],
      "metadata": {
        "id": "4pMk4RxPS9JB"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs=epochs, batch_size=batch_size, callbacks=callbacks_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fvkcXeuTFB3",
        "outputId": "c429ba9c-777a-48d4-aea9-24ae110e1532"
      },
      "execution_count": 20,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1279/1279 [==============================] - ETA: 0s - loss: 2.9943\n",
            "Epoch 1: loss improved from inf to 2.99433, saving model to weights-improvement-01-2.9943.hdf5\n",
            "1279/1279 [==============================] - 868s 676ms/step - loss: 2.9943\n",
            "Epoch 2/3\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1279/1279 [==============================] - ETA: 0s - loss: 2.8053\n",
            "Epoch 2: loss improved from 2.99433 to 2.80530, saving model to weights-improvement-02-2.8053.hdf5\n",
            "1279/1279 [==============================] - 836s 654ms/step - loss: 2.8053\n",
            "Epoch 3/3\n",
            "1279/1279 [==============================] - ETA: 0s - loss: 2.7291\n",
            "Epoch 3: loss improved from 2.80530 to 2.72908, saving model to weights-improvement-03-2.7291.hdf5\n",
            "1279/1279 [==============================] - 830s 649ms/step - loss: 2.7291\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x783cf6c70250>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Greating text with LSTM Model**"
      ],
      "metadata": {
        "id": "AsB4nCU_ZD7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load the network weights\n",
        "filename = \"weights-improvement-03-2.7291.hdf5\"\n",
        "# 2.3100 IS MINIMUM LOSS and we have to enter our minimum loss here\n",
        "# 02 is number of epochs\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "5i0TevaoTVDZ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int_to_char = dict((i,c) for i,c in enumerate(chars))"
      ],
      "metadata": {
        "id": "UIfwXLuEbtCw"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Gerenate Random seed\n",
        "#generate random set of characters and find what is the next 100 words\n",
        "\n",
        "print(len(dataX))\n",
        "\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "print(start)\n",
        "pattern = dataX[start] #dataX contains list of patters\n",
        "print(\"Seed : \")\n",
        "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2Y5wC9kZobY",
        "outputId": "ca8cc40d-3102-4c3f-8097-e5f60e4e8399"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "163680\n",
            "43822\n",
            "Seed : \n",
            "\" mong\n",
            "the trees, a little sharp bark just over her head made her look up in a\n",
            "great hurry.\n",
            "\n",
            "an enormo \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate Characters\n",
        "length = 10\n",
        "final = []\n",
        "\n",
        "for i in range(length):\n",
        "\n",
        "  #reshaping the seed sequence before passing it into LSTM model\n",
        "  x = numpy.reshape(pattern, (1,len(pattern),1))\n",
        "  # print(x)\n",
        "\n",
        "  #normalizing the integer values\n",
        "  x = x/float(n_vocab)\n",
        "  # print(x)\n",
        "\n",
        "  #making prediction\n",
        "  prediction = model.predict(x, verbose=0)\n",
        "\n",
        "  #get the predicted value with maximum probability\n",
        "  index = numpy.argmax(prediction)\n",
        "\n",
        "  #Convert the prediction integer to char\n",
        "  result = int_to_char[index]\n",
        "  print(result)\n",
        "  final.append(result)\n",
        "\n",
        "  #Adding the predicted characters to the sequence\n",
        "  pattern.append(index)\n",
        "\n",
        "  #Removing the first character from the seed sequence\n",
        "  pattern = pattern[1:len(pattern)]\n",
        "\n",
        "print(final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsgODWUacBdh",
        "outputId": "2c60a2d7-0136-49c4-a5b2-42ab85a92c7f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "t\n",
            "o\n",
            "e\n",
            " \n",
            "t\n",
            "o\n",
            "e\n",
            "t\n",
            " \n",
            "[' ', 't', 'o', 'e', ' ', 't', 'o', 'e', 't', ' ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %tensorflow_version 2.X\n",
        "\n",
        "# import tensorflow as tf\n",
        "\n",
        "# device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# if device_name != '/device:GPU:0':\n",
        "#   raise SystemError('GPU device not found')\n",
        "# print('Found GPU at : {}'.format(device_name))"
      ],
      "metadata": {
        "id": "tBvUejv1dvBw"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mNCf2J3ZD7D9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}